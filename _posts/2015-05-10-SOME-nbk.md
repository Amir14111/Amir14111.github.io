---
layout: post
title: Stacking
---


#### О том как можно реализовать стекинг...

в этом туторе рассмотрена техника ансамблирования моделей - стекинг и блендинг с технической стороны. 

коротко о том, что я под этим подразумеваю:

Стекинг - когда мы на данных обучаем несколько различных моделей, а потом на их предсказаниях обучаем еще одну и берем ее ответы.

Блендинг - просто взвешенная сумма ответов нескольких различных моделей.



```python
import numpy as np
import pandas as pd
from sklearn.cross_validation import train_test_split
from sklearn.cross_validation import cross_val_predict, StratifiedKFold
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import roc_auc_score

```


```python
# итак считаем какие-то данные
dt = pd.read_csv('log_data.csv', header=None, names=['target', 'x1', 'x2'])
```


```python
dt.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>target</th>
      <th>x1</th>
      <th>x2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-1</td>
      <td>-0.663827</td>
      <td>-0.138526</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1.994596</td>
      <td>2.468025</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-1</td>
      <td>-1.247395</td>
      <td>0.749425</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>2.309374</td>
      <td>1.899836</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>0.849143</td>
      <td>2.407750</td>
    </tr>
  </tbody>
</table>
</div>




```python
X = dt[['x1','x2']].values
y = dt['target'].values
```


```python

```


```python
# разделим на трейн и тест 
X, X_test, y, y_test = train_test_split(X, y, test_size=0.3, random_state=1234, stratify = y)
```


```python
# зададим  разбиение и не будем его менять
skf = StratifiedKFold(y, n_folds=6, random_state=0)
```


```python

```

ok!

мы сказали, что нам как то нужно обучить наши модели на первом уровне, а потом предсказания объединить в матрицу и на них обучить еще одну модель.

Все круто, но хотелось бы использовать все данные которые есть для обучения моделей первого уровня, при этом обучить и получить их предсказания честно. Для этого поступим следующим образом. 

(снизу рисунок получения данных для одной модели первого уровня)

- Зафиксируем разбиение
- Кросс-валидацией будем обучать модель и предсказывать на оставшейся части данных вероятности (можно и ответы)
    * при этом будем соблюдать чтобы на выходе получился вектор ответов и ответы совпадали с данными для которых предсказывали (это сделано для того чтобы можно было обучить модель второго уровня с тем же вектором таргета)
    * после того как получили данные для обучения модели второго уровня, можно обучать на всех данных модели первого уровня (без кросс-валидации взять и обучить!)
- Взять ответы и тот же таргет и на них обучить поверх еще одну модель.

+++ предсказания:

- предсказываем ответы моделей первого уровня.
- в том же порядке стакаем матрицу и получаем предсказания с модели второго уровня - - - это и есть финальный ответ

![okey](excelcvpp.png)


```python

```


```python

```

### как мы можем получать такую матричку для моделек первого уровня?

#### способ 1


```python
def cross_val_predict_proba(estimator, skf, X, y):
    """
    выдает вектор заполненный так: учимся на N-1 фолдах, предсказываем на 1, заполняем вероятности 
    ровно тех индексов, на которых предсказывали. берем другие N-1 фолдов и тд... и так пока не пройдем все
    """
    res = np.zeros(y.shape)
    for train, test in skf:
        estimator.fit(X[train], y[train])
        res[test] = estimator.predict_proba(X[test])
    return res
```


```python
### эти ответы со всех моделей первого уровня можно склеить (застакать) вот так
a = np.array([1,1,1,1,1,1])
b = np.array([0,0,0,1,1,1])
c = np.array([1,1,1,0,0,0])

d = np.vstack([a,b,c]).T
```


```python
d
```




    array([[1, 0, 1],
           [1, 0, 1],
           [1, 0, 1],
           [1, 1, 0],
           [1, 1, 0],
           [1, 1, 0]])



#### ну или способ 2.

заделаем класс-обертку в который завернем свой классификатор

зачем?

чтобы честно заполнять предсказания с перового уровня с помощью функции cross_val_predict (и не пилить свое cross_val_predict_proba):
http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.cross_val_predict.html



```python
from sklearn.base import BaseEstimator

# то есть создадим класс обертку который будет выдавать только вероятности (даже когда будем просить ответы!)
class Only_proba_classifier(BaseEstimator):
    def __init__(self, clf):
        self.clf = clf
        
    def fit(self, X, y):
        self.clf.fit(X, y)
        return self
    
    def predict(self, X):
        return self.clf.predict_proba(X)
    
    def predict_proba(self, X):
        return self.clf.predict_proba(X)
```


```python

```

Тогда он будет работать вот так:

cross_val_predict(Only_proba_classifier(clf), X, y, cv=skf)

но с разных моделей стакать (склеивать) результаты все равно придется руками.


```python

```

### Перейдем к делу взяв способ номер 2


```python
# возьмем RandomForest в качестве одного из классификаторов

clf_rf = RandomForestClassifier(random_state=0)

# заполним матрицу предсказаний вероятностями 
preds_rf = cross_val_predict(Only_proba_classifier(clf_rf), X, y, cv=skf) 

# обучим модель на всех данных
clf_rf.fit(X, y)


### сразу сделаем предсказания для теста.
preds_test_rf = clf_rf.predict_proba(X_test)
```


```python
# возьмем LogisticRegression в качестве другого классификатора
sc = MinMaxScaler()
clf_lr = LogisticRegression(random_state=0)

# заполним матрицу предсказаний вероятностями
preds_lr = cross_val_predict(Only_proba_classifier(clf_lr), sc.fit_transform(X), y, cv=skf)


# обучим модель на всех данных
clf_lr.fit(sc.transform(X), y)


### сразу сделаем предсказания для теста.
preds_test_lr = clf_lr.predict_proba(sc.transform(X_test))
```


```python
### результаты с кроссвалидации

print ('Random Forest: {0:0.3f}'.format(roc_auc_score(y, preds_rf[:, 1])))
print ('Logistic Regression: {0:0.3f}'.format(roc_auc_score(y, preds_lr[:, 1])))
```

    Random Forest: 0.933
    Logistic Regression: 0.888



```python

```


```python
### на тесте 
print ('Random Forest test: {0:0.3f}'.format(roc_auc_score(y_test, preds_test_rf[:, 1])))
print ('Logistic Regression test: {0:0.3f}'.format(roc_auc_score(y_test, preds_test_lr[:, 1])))
```

    Random Forest test: 0.961
    Logistic Regression test: 0.931


____

Итак Blending

Говорят - это просто взвешенная сумма предсказаний (можно подбирать перебором, можно на глаз, можно опираться
на предсказательную силу классификатора или на лидерборд)


```python
%matplotlib inline
import matplotlib.pyplot as plt
```


```python
weights = np.linspace(0, 1, 100)
scores = np.zeros_like(weights)

for index, alpha in enumerate(weights):
    preds = alpha * preds_rf + (1-alpha) * preds_lr
    score = roc_auc_score(y, preds[:, 1])
    scores[index] = score

plt.plot(weights, scores)
print ('Best roc auc score: {0:0.3f}'.format(scores.max()))
print ('Best alpha: {0:0.3f}'.format(weights[scores.argmax()]))
```

    Best roc auc score: 0.948
    Best alpha: 0.717



![png](output_33_1.png)



```python
alpha = 0.717

final_blending_prediction = alpha * preds_test_rf + (1-alpha) * preds_test_lr
```


```python
print ('Blending on test: {0:0.3f}'.format( roc_auc_score(y_test, final_blending_prediction[:, 1]) ))
```

    Blending on test: 0.973


_____

еще есть стекинг __stacking__

тут мы второй моделью взвешиваем результаты первых


```python
### склеиваем данные для трейна и теста  соответственно
train_stacking = np.hstack([preds_rf, preds_lr])
test_stacking = np.hstack([preds_test_rf, preds_test_lr])
```

возьмем моделью второго уровня - логрегрессию:


```python
lr_stacking = LogisticRegression()
lr_stacking.fit(train_stacking, y)
print ('stacking train: {0:0.3f}'.format(roc_auc_score(y,    lr_stacking.predict_proba(train_stacking)[:,1] )))
print ('stacking test: {0:0.3f}'.format(roc_auc_score(y_test, lr_stacking.predict_proba(test_stacking)[:,1] )))
```

    stacking train: 0.948
    stacking test: 0.973



```python
# попробуем потюнить
lr_stacking = LogisticRegression(C=1e-4, fit_intercept=False)
lr_stacking.fit(train_stacking, y)
print ('stacking optimizing train: {0:0.3f}'.format(roc_auc_score(y,    lr_stacking.predict_proba(train_stacking)[:,1] )))
print ('stacking optimizing test: {0:0.3f}'.format(roc_auc_score(y_test, lr_stacking.predict_proba(test_stacking)[:,1] )))
```

    stacking optimizing train: 0.949
    stacking optimizing test: 0.972



```python

```


```python

```


```python

```
